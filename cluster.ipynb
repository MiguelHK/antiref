{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9bce4ad",
   "metadata": {},
   "source": [
    "## AntiRef: identity clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae42275-eb34-4c8e-84c3-2e67dd618089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install pandas tqdm abutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dfecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import abutils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10ea347b",
   "metadata": {},
   "source": [
    "#### build the initial MMSeqs2 database\n",
    "\n",
    "`mmseqs linclust` requires an MMSeqs2 database as input (not a FASTA file), so we first need to create a database of the filtered input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mmseqs_db(\n",
    "    fasta_path: str,\n",
    "    db_path: str,\n",
    "    debug: bool = False,\n",
    ") -> Optional[Iterable[str]]:\n",
    "    '''\n",
    "    Builds an MMSeqs2 database from a FASTA-formatted input file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fasta_path : str\n",
    "        Path to a FASTA-formatted input file. Required.\n",
    "\n",
    "    db_path : str\n",
    "        Path for the MMSeqs2 database. If it does not exist, it will be created. \n",
    "        Required.\n",
    "\n",
    "    debug : bool, default=False\n",
    "        If ``True``, the ``stdout`` and ``stderr`` from running ``mmseqs`` will be\n",
    "        returned. If ``False``, nothing is returned. Default is ``False``.\n",
    "    '''\n",
    "    fasta_path = os.path.abspath(fasta_path)\n",
    "    db_path = os.path.abspath(db_path)\n",
    "    if not os.path.isdir(os.path.dirname(db_path)):\n",
    "        abutils.io.makedir(os.path.dirname(db_path))\n",
    "    createdb = f\"mmseqs createdb {fasta_path} {db_path}\"\n",
    "    p = sp.Popen(createdb, shell=True, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    stdout, stderr = p.communicate()\n",
    "    if debug:\n",
    "        return stdout, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fasta = './data/filtered/fasta/all.fasta'\n",
    "init_db = './data/antiref/seqdb/init'\n",
    "\n",
    "make_mmseqs_db(\n",
    "    fasta_path=init_fasta,\n",
    "    db_path=init_db,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f3d4ea3",
   "metadata": {},
   "source": [
    "### cluster AntiRef datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d21181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linclust(\n",
    "    threshold: int,\n",
    "    parent_db: str,\n",
    "    temp_dir: str = '/tmp',\n",
    "    debug: bool = False,\n",
    ") -> Optional[Iterable[str]]:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # set up file and DB paths\n",
    "    temp_dir = os.path.abspath(temp_dir)\n",
    "    parent_db = os.path.abspath(parent_db)\n",
    "    cluster_db = f\"./data/antiref/clusterdb/antiref{threshold}\"\n",
    "    seq_db = f\"./data/antiref/seqdb/antiref{threshold}\"\n",
    "    seq_tsv = f\"./data/antiref/tsv/antiref{threshold}.tsv\"\n",
    "    cluster_sizes = f\"./data/antiref/tsv/antiref{threshold}_cluster-sizes.csv\"\n",
    "    seq_fasta = f\"./data/antiref/fasta/antiref{threshold}.fasta\"\n",
    "    for path in [cluster_db, seq_db, seq_tsv, seq_fasta]:\n",
    "        d = os.path.dirname(path)\n",
    "        if not os.path.isdir(d):\n",
    "            abutils.io.make_dir(d)\n",
    "    # do the clustering\n",
    "    cmd = f\"mmseqs linclust {parent_db} {cluster_db} {temp_dir} \"\n",
    "    cmd += \"--cov-mode 0 \"\n",
    "    cmd += \"-c 1.0 \"\n",
    "    cmd += f\"--min-seq-id {threshold/100:0.2f} \"\n",
    "    cmd += f\"&& mmseqs createsubdb {cluster_db} {parent_db} {seq_db} \"\n",
    "    cmd += f\"&& mmseqs convert2fasta {seq_db} {seq_fasta} \"\n",
    "    cmd += f\"&& mmseqs createtsv {parent_db} {parent_db} {cluster_db} {seq_tsv} \"\n",
    "    cmd += f\"&& cut -f 1 {seq_tsv} | sort | uniq -c > {cluster_sizes} \"\n",
    "    if debug:\n",
    "        print('')\n",
    "        print(cmd)\n",
    "        print('')\n",
    "    p = sp.Popen(cmd, shell=True, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    stdout, stderr = p.communicate()\n",
    "    if debug:\n",
    "        return stdout, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [100, 99, 98, 96, 94, 92, 90]\n",
    "parent_lookup = {\n",
    "    100: \"./data/antiref/seqdb/init\",\n",
    "    99: \"./data/antiref/seqdb/antiref100\",\n",
    "    98: \"./data/antiref/seqdb/antiref99\",\n",
    "    96: \"./data/antiref/seqdb/antiref98\",\n",
    "    94: \"./data/antiref/seqdb/antiref96\",\n",
    "    92: \"./data/antiref/seqdb/antiref94\",\n",
    "    90: \"./data/antiref/seqdb/antiref92\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed69526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    parent_db = parent_lookup[threshold]\n",
    "    print(f'clustering at {threshold/100:0.2f} identity using linclust...')\n",
    "    print(f'  - parent: {parent_db}')\n",
    "    sys.stdout.flush()\n",
    "    linclust(\n",
    "        threshold=threshold,\n",
    "        parent_db=parent_db,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef48b068",
   "metadata": {},
   "source": [
    "### cluster manifest\n",
    "\n",
    "The cluster manifest is a CSV file of the format:\n",
    "\n",
    "| antiref100 | antiref99 | antiref98 | antiref96 | antiref04 | antiref92 | antiref90 |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| id_01 | id_01 | id_01 | id_01 | id_01 | id_01 | id_03 |\n",
    "| id_02 | id_01 | id_01 | id_01 | id_01 | id_01 | id_03 |\n",
    "| id_03 | id_03 | id_03 | id_03 | id_03 | id_03 | id_03 |\n",
    "| id_04 | id_04 | id_04 | id_04 | id_04 | id_04 | id_04 |\n",
    "| id_05 | id_05 | id_05 | id_05 | id_05 | id_05 | id_05 |\n",
    "\n",
    "To interpret the cluster manifest, it's important to remember that we perform nested clustering, and that cluster names are taken from the representative sequence in the cluster (as determined by `mmseqs`). Walking through this mock data, we observe several things:\n",
    "\n",
    "1. The sequences `id_01` and `id_02` are at least 99% similar but not identical, as they are separate in AntiRef100 but merge in AntiRef99\n",
    "2. `id_01` becomes the representative sequence in the AntiRef99 cluster containing `id_01` and `id_02` \n",
    "3. The sequence `id_03` is 90-92% similar to `id_01` and `id_02` and becomes the representative of the resulting AntiRef90 cluster\n",
    "4. The sequences `id_04` and `id_05` are less than 90% similar to each other and to `id_01`, `id_02`, and `id_03`.\n",
    "\n",
    "The manifest can also be used to infer the relative diversity of any AntiRef cluster. If we filter AntiRef90 cluster `id_03`, we can quickly determine that two of the three sequences are nearly identical. Extrapolating this, an AntiRef90 cluster containing 100 sequences of which 99 clustered together in AntiRef99 is much less diverse than the same size AntiRef90 cluster for which none of the sequences clustered together in of the higher identity AntiRef clusters.\n",
    "\n",
    "To create the cluster manifest, we first need to iterate through all of the AntiRef datasets and parse the cluster assignments. The result is a single nested dictionary with results for all AntiRef datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a002d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dicts = {}\n",
    "pbar = tqdm(thresholds)\n",
    "\n",
    "for threshold in pbar:\n",
    "    d = {}\n",
    "    pbar.set_description(f\"AntiRef{threshold}\")\n",
    "    with open(f\"./data/antiref/tsv/antiref{threshold}.tsv\") as f:\n",
    "        for line in f:\n",
    "            if l := line.strip().split():\n",
    "                d[l[1]] = l[0]\n",
    "    cluster_dicts[threshold] = d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f438da13",
   "metadata": {},
   "source": [
    "We can then and write the results as a CSV-formatted file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_csv = './data/antiref/antiref_cluster-manifest.csv'\n",
    "if not os.path.isdir(os.path.dirname(manifest_csv)):\n",
    "    abutils.io.make_dir(os.path.dirname(manifest_csv))\n",
    "\n",
    "with open(manifest_csv, 'w') as f:\n",
    "    header = [f'antiref{c}' for c in thresholds]\n",
    "    f.write(','.join(header) + '\\n')\n",
    "    all_names = list(cluster_dicts[99].keys())\n",
    "    for c100 in tqdm(all_names):\n",
    "        c99 = cluster_dicts[99][c100]\n",
    "        c98 = cluster_dicts[98][c99]\n",
    "        c96 = cluster_dicts[96][c98]\n",
    "        c94 = cluster_dicts[94][c96]\n",
    "        c92 = cluster_dicts[92][c94]\n",
    "        c90 = cluster_dicts[90][c92]\n",
    "        f.write(','.join([c100, c99, c98, c96, c94, c92, c90]) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "787b565a",
   "metadata": {},
   "source": [
    "### clustering efficiency\n",
    "\n",
    "Finally, we'll quantify dataset compression for each AntiRef dataset. The result is a CSV-formatted file of the format:\n",
    "\n",
    "| clustering_identity | clusters | efficiency |\n",
    "| --- | --- | --- |\n",
    "| 100 | 100,000,000 | 1.00 |\n",
    "| 99 | 90,000,000 | 0.90 |\n",
    "| 98 | 88,000,000 | 0.88 |\n",
    "\n",
    "The efficiency is computed relative to AntiRef100, which contains all of the unique sequences from the filtered input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d44763",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_path = './data/antiref/clustering_efficiencies.csv'\n",
    "if not os.path.isdir(os.path.dirname(eff_path)):\n",
    "    abutils.io.make_dir(os.path.dirname(eff_path))\n",
    "\n",
    "eff_data = []\n",
    "antiref100_count = None\n",
    "\n",
    "pbar = tqdm(thresholds)\n",
    "for threshold in pbar:\n",
    "    pbar.set_description(f\"AntiRef{threshold}\")\n",
    "    size_path = os.path.abspath(f\"./data/antiref/tsv/antiref{threshold}_cluster-sizes.csv\")\n",
    "\n",
    "    # find the dataset size by counting the number lines in the cluster_sizes CSV file\n",
    "    wc = f\"wc -l {size_path}\"\n",
    "    p = sp.Popen(wc, shell=True, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    stdout, _ = p.communicate()\n",
    "    count = int(stdout.decode('utf-8').split()[0])\n",
    "\n",
    "    # set AntiRef100 count for dataset size normalization\n",
    "    if threshold == 100:\n",
    "        antiref100_count = count\n",
    "    \n",
    "    eff_data.append({'clustering_identity': threshold,\n",
    "                     'clusters': count,\n",
    "                     'efficiency': count / antiref100_count})\n",
    "\n",
    "# save efficiency data\n",
    "eff_df = pd.DataFrame(eff_data)\n",
    "eff_df.to_csv(eff_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574cec97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
